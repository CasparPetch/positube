{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93eb2be-4dd9-4410-87aa-2248408294d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth-oauthlib (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth-oauthlib (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c56c4b-8df1-4793-b21b-1a01815115d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth-oauthlib (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas_gbq in /opt/conda/lib/python3.10/site-packages (0.19.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (67.7.2)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (9.0.0)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.8.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.11.0)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (3.10.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.16.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from db-dtypes<2.0.0,>=1.0.4->pandas_gbq) (23.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.57.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.19.6)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.28.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (1.3.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.48.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.22.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->pandas_gbq) (2023.3)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.48.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas_gbq) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2022.12.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth-oauthlib (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install pandas_gbq\n",
    "import pandas_gbq\n",
    "\n",
    "from google.cloud import bigquery\n",
    "bqclient = bigquery.Client()\n",
    "\n",
    "project_id = \"positube-389309\"\n",
    "# dataset_id = \"comments_dataset_dislikes\"\n",
    "# table_id = \"video_score_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd0e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:04:11.458225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 16:04:12.372777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-09 16:04:12.372910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-09 16:04:12.372922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70199880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a36dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:04:16.902535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:16.914883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:16.916600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:16.918684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 16:04:16.919576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:16.921244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:16.922869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:17.807512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:17.809461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:17.811103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 16:04:17.812673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb0e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGdf = pd.read_csv('final_df_CLEAN.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6013edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIGdf = BIGdf[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099a2364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likecount</th>\n",
       "      <th>date</th>\n",
       "      <th>replies</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respect to Dortmund fans must be sad losing him.</td>\n",
       "      <td>Uh Idk</td>\n",
       "      <td>1932</td>\n",
       "      <td>2021-07-01T10:33:16Z</td>\n",
       "      <td>59</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real talent  hope he doesn't turn into anoth...</td>\n",
       "      <td>7h35h96u9</td>\n",
       "      <td>617</td>\n",
       "      <td>2021-07-01T10:28:25Z</td>\n",
       "      <td>34</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wish him well in manchester united</td>\n",
       "      <td>Guncius</td>\n",
       "      <td>2583</td>\n",
       "      <td>2021-07-01T10:01:00Z</td>\n",
       "      <td>94</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most talented players Bundesliga ha...</td>\n",
       "      <td>Rishi Joe Sanu</td>\n",
       "      <td>57</td>\n",
       "      <td>2021-07-01T12:46:06Z</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a spell in the Bundesliga  Goodluck in th...</td>\n",
       "      <td>H2KAL5859</td>\n",
       "      <td>66</td>\n",
       "      <td>2021-07-01T10:01:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Ye killed it! The spiritual mix in music is â€œh...</td>\n",
       "      <td>Jay Bee</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-08-06T19:50:49Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>An AMAZING EMOTIONAL ENCYCLOPEDIA OF SOME Of T...</td>\n",
       "      <td>RoseBud20</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-07T22:21:50Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Facts or undeniable facts?...Kanye West needs ...</td>\n",
       "      <td>The Alkebulan Trust</td>\n",
       "      <td>46</td>\n",
       "      <td>2021-08-06T12:11:17Z</td>\n",
       "      <td>2</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Hate him or love him he is the greatest artist...</td>\n",
       "      <td>Bryan Kicks</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-06T20:21:12Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>I don't get why I don't hear people put Kanye ...</td>\n",
       "      <td>Basslivesmatter LLC</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-07T20:05:54Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment               author  \\\n",
       "0     Respect to Dortmund fans must be sad losing him.               Uh Idk   \n",
       "1    A real talent  hope he doesn't turn into anoth...            7h35h96u9   \n",
       "2                   wish him well in manchester united              Guncius   \n",
       "3    One of the most talented players Bundesliga ha...       Rishi Joe Sanu   \n",
       "4    What a spell in the Bundesliga  Goodluck in th...            H2KAL5859   \n",
       "..                                                 ...                  ...   \n",
       "495  Ye killed it! The spiritual mix in music is â€œh...              Jay Bee   \n",
       "496  An AMAZING EMOTIONAL ENCYCLOPEDIA OF SOME Of T...            RoseBud20   \n",
       "497  Facts or undeniable facts?...Kanye West needs ...  The Alkebulan Trust   \n",
       "498  Hate him or love him he is the greatest artist...          Bryan Kicks   \n",
       "499  I don't get why I don't hear people put Kanye ...  Basslivesmatter LLC   \n",
       "\n",
       "     likecount                  date  replies     video_id  \n",
       "0         1932  2021-07-01T10:33:16Z       59  --0bCF-iK2E  \n",
       "1          617  2021-07-01T10:28:25Z       34  --0bCF-iK2E  \n",
       "2         2583  2021-07-01T10:01:00Z       94  --0bCF-iK2E  \n",
       "3           57  2021-07-01T12:46:06Z        1  --0bCF-iK2E  \n",
       "4           66  2021-07-01T10:01:31Z        0  --0bCF-iK2E  \n",
       "..         ...                   ...      ...          ...  \n",
       "495          2  2021-08-06T19:50:49Z        0  -0PZSxZuAXQ  \n",
       "496          0  2021-08-07T22:21:50Z        0  -0PZSxZuAXQ  \n",
       "497         46  2021-08-06T12:11:17Z        2  -0PZSxZuAXQ  \n",
       "498          0  2021-08-06T20:21:12Z        0  -0PZSxZuAXQ  \n",
       "499          0  2021-08-07T20:05:54Z        0  -0PZSxZuAXQ  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a8c1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      --0bCF-iK2E\n",
       "1      --0bCF-iK2E\n",
       "2      --0bCF-iK2E\n",
       "3      --0bCF-iK2E\n",
       "4      --0bCF-iK2E\n",
       "          ...     \n",
       "495    -0PZSxZuAXQ\n",
       "496    -0PZSxZuAXQ\n",
       "497    -0PZSxZuAXQ\n",
       "498    -0PZSxZuAXQ\n",
       "499    -0PZSxZuAXQ\n",
       "Name: video_id, Length: 500, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e278ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['--0bCF-iK2E', '--DKkzWVh-E', '-024Swollbc', '-0PZSxZuAXQ'], dtype='object', name='video_id')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf.value_counts('video_id').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a281ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f6e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_weights(num):\n",
    "    '''This function makes weights for each comment based on its like count (num)'''\n",
    "    if num == 0:\n",
    "        return 1\n",
    "    elif num > 0 and num <= np.median(likes[:len(likes)//2]):\n",
    "        return 2\n",
    "    elif num > np.median(likes[:len(likes)//2]) and num <= np.median(likes):\n",
    "        return 3\n",
    "    elif num > np.median(likes) and num < np.median(likes[len(likes)//2:]):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f9fef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cutter(df):\n",
    "    IDs_list = df.value_counts('video_id').keys()\n",
    "    cut_dfs = []\n",
    "    for i, video in enumerate(IDs_list):\n",
    "        cut_df = df[df['video_id'] == IDs_list[i]].copy()\n",
    "        global likes\n",
    "        likes = sorted(list(cut_df[cut_df['likecount'] > 0]['likecount']))\n",
    "        cut_df['weight'] = cut_df['likecount'].apply(making_weights)\n",
    "        cut_dfs.append(cut_df.copy())\n",
    "    return cut_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c2dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_dfs = df_cutter(BIGdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f28c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_comment(df):\n",
    "\n",
    "    '''This function predicts the sentiment score of each youtube video!'''\n",
    "    \n",
    "    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Lists to store the sentiment analysis results\n",
    "    sentiment_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    positive_list = []\n",
    "    scalar_value_list = []\n",
    "    weighted_SV = []\n",
    "    weight = list(df['likecount'].apply(making_weights))\n",
    "\n",
    "    # Iterate over the comments in the DataFrame\n",
    "    for i, text in enumerate(df['comment']):\n",
    "        \n",
    "        # Tokenization, Sentiment Prediction, and Interpretation\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, padding='longest', truncation=True, max_length=512, return_tensors='tf')\n",
    "        outputs = model(tokens.input_ids)\n",
    "        logits = outputs.logits\n",
    "        prediction = np.array(tf.nn.softmax(logits)[0])\n",
    "        predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "        sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "        predicted_sentiment = sentiment_labels[predicted_class]\n",
    "\n",
    "        # Append the sentiment analysis results to the respective lists\n",
    "        sentiment_list.append(predicted_sentiment)\n",
    "        negative_list.append(round(prediction[0]*100, 2))\n",
    "        neutral_list.append(round(prediction[1]*100, 2))\n",
    "        positive_list.append(round(prediction[2]*100, 2))\n",
    "        scalar_value_val = round((prediction[0])*-1+(prediction[2]*1),2)\n",
    "        scalar_value_list.append(scalar_value_val)\n",
    "        weighted_SV.append(df['weight'].iloc[i] * scalar_value_val)\n",
    "\n",
    "\n",
    "    # Create a new DataFrame with the sentiment analysis results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Comment': df['comment'],\n",
    "        'Sentiment': sentiment_list,\n",
    "        'Negative_percent': negative_list,\n",
    "        'Neutral_percent': neutral_list,\n",
    "        'Positive_percent': positive_list,\n",
    "        'Scaler_value': scalar_value_list,\n",
    "        'weighted_SV': weighted_SV,\n",
    "        'weight': weight\n",
    "    })\n",
    "\n",
    "    # Return the new DataFrame\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00284ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DID THIS VIDEO  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 8035.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND NOW IT IS ON BIG QUERY \n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DID THIS VIDEO  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3934.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND NOW IT IS ON BIG QUERY \n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DID THIS VIDEO  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 9510.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND NOW IT IS ON BIG QUERY \n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DID THIS VIDEO  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 9098.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND NOW IT IS ON BIG QUERY \n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                               Comment Sentiment  \\\n",
       " 0     Respect to Dortmund fans must be sad losing him.   Neutral   \n",
       " 1    A real talent  hope he doesn't turn into anoth...   Neutral   \n",
       " 2                   wish him well in manchester united  Positive   \n",
       " 3    One of the most talented players Bundesliga ha...  Positive   \n",
       " 4    What a spell in the Bundesliga  Goodluck in th...  Positive   \n",
       " ..                                                 ...       ...   \n",
       " 170         Has potential to be the next Ronaldo/messi  Positive   \n",
       " 171                              Sancho <3  Thank you.  Positive   \n",
       " 172  Welcome to Manchester United the theatre of dr...  Positive   \n",
       " 173  I hope he became much stronger and healthier i...  Positive   \n",
       " 174  All i can say is  good luck on your next desti...  Positive   \n",
       " \n",
       "      Negative_percent  Neutral_percent  Positive_percent  Scaler_value  \\\n",
       " 0               33.80            50.22             15.98         -0.18   \n",
       " 1               10.69            63.89             25.42          0.15   \n",
       " 2                0.31            11.78             87.91          0.88   \n",
       " 3                0.22             1.68             98.10          0.98   \n",
       " 4                0.18             3.56             96.26          0.96   \n",
       " ..                ...              ...               ...           ...   \n",
       " 170              0.86            35.08             64.07          0.63   \n",
       " 171              0.21             7.30             92.49          0.92   \n",
       " 172              0.17             6.92             92.91          0.93   \n",
       " 173              0.14             2.31             97.56          0.97   \n",
       " 174              0.28             1.31             98.41          0.98   \n",
       " \n",
       "      weighted_SV  weight     video_id  \n",
       " 0          -0.90       5  --0bCF-iK2E  \n",
       " 1           0.75       5  --0bCF-iK2E  \n",
       " 2           4.40       5  --0bCF-iK2E  \n",
       " 3           4.90       3  --0bCF-iK2E  \n",
       " 4           4.80       4  --0bCF-iK2E  \n",
       " ..           ...     ...          ...  \n",
       " 170         0.63       1  --0bCF-iK2E  \n",
       " 171         3.68       2  --0bCF-iK2E  \n",
       " 172         1.86       2  --0bCF-iK2E  \n",
       " 173         1.94       2  --0bCF-iK2E  \n",
       " 174         0.98       1  --0bCF-iK2E  \n",
       " \n",
       " [175 rows x 9 columns],\n",
       "                                                Comment Sentiment  \\\n",
       " 175  ðŸš§ Keep up with all my projects here: https://p...  Positive   \n",
       " 176  Your mechanically stabilized earth video inspi...  Positive   \n",
       " 177  As a professional landscapers who has built qu...   Neutral   \n",
       " 178  I love that heâ€™s a civil engineer and his name...  Positive   \n",
       " 179  Thanks to videos like these I massively overde...  Positive   \n",
       " ..                                                 ...       ...   \n",
       " 327  One of the most deadly things on construction ...  Negative   \n",
       " 328  I love watching your videos  there's always so...  Positive   \n",
       " 329  As an old renovator and retention wall builder...   Neutral   \n",
       " 330  Great video  but you need a 2:1 or 4:1 audio c...   Neutral   \n",
       " 331  Yet another excellent video about engineering....  Positive   \n",
       " \n",
       "      Negative_percent  Neutral_percent  Positive_percent  Scaler_value  \\\n",
       " 175              0.29            30.31             69.40          0.69   \n",
       " 176              0.60            35.77             63.63          0.63   \n",
       " 177              5.11            69.74             25.16          0.20   \n",
       " 178              0.22             1.97             97.81          0.98   \n",
       " 179              0.58            11.11             88.31          0.88   \n",
       " ..                ...              ...               ...           ...   \n",
       " 327             93.27             6.16              0.57         -0.93   \n",
       " 328              0.19             1.07             98.73          0.99   \n",
       " 329             17.92            62.37             19.71          0.02   \n",
       " 330             31.16            49.34             19.49         -0.12   \n",
       " 331              0.47             5.78             93.76          0.93   \n",
       " \n",
       "      weighted_SV  weight     video_id  \n",
       " 175         3.45       5  --DKkzWVh-E  \n",
       " 176         3.15       5  --DKkzWVh-E  \n",
       " 177         1.00       4  --DKkzWVh-E  \n",
       " 178         4.90       4  --DKkzWVh-E  \n",
       " 179         3.52       3  --DKkzWVh-E  \n",
       " ..           ...     ...          ...  \n",
       " 327        -3.72       3  --DKkzWVh-E  \n",
       " 328         0.99       1  --DKkzWVh-E  \n",
       " 329         0.02       1  --DKkzWVh-E  \n",
       " 330        -0.12       1  --DKkzWVh-E  \n",
       " 331         2.79       2  --DKkzWVh-E  \n",
       " \n",
       " [157 rows x 9 columns],\n",
       "                                                Comment Sentiment  \\\n",
       " 332  This man is great. He gives his daughter priva...  Positive   \n",
       " 333  Man is a genius  going to get to write that of...  Positive   \n",
       " 334       This is obviously more important than school   Neutral   \n",
       " 335  Jared seems like a great person. For sure gonn...  Positive   \n",
       " 336  The dislikes are the people who didnâ€™t get the...  Negative   \n",
       " ..                                                 ...       ...   \n",
       " 427  I love these videos Iâ€™ve watched every single ...  Positive   \n",
       " 428  Jared is a sound person I think you should all...  Positive   \n",
       " 429  I just got out of the hospital for something y...  Positive   \n",
       " 430                               Love the videos seth  Positive   \n",
       " 431  As some one who is from Louisiana our trails c...   Neutral   \n",
       " \n",
       "      Negative_percent  Neutral_percent  Positive_percent  Scaler_value  \\\n",
       " 332              0.23             2.03             97.75          0.98   \n",
       " 333              0.47            10.17             89.36          0.89   \n",
       " 334             28.34            48.12             23.54         -0.05   \n",
       " 335              3.37            11.56             85.07          0.82   \n",
       " 336             74.52            23.48              2.00         -0.73   \n",
       " ..                ...              ...               ...           ...   \n",
       " 427              0.24             0.89             98.88          0.99   \n",
       " 428              0.39             8.92             90.69          0.90   \n",
       " 429             22.48            33.52             44.01          0.22   \n",
       " 430              0.21             1.38             98.41          0.98   \n",
       " 431             10.57            70.16             19.28          0.09   \n",
       " \n",
       "      weighted_SV  weight     video_id  \n",
       " 332         4.90       5  -024Swollbc  \n",
       " 333         4.45       3  -024Swollbc  \n",
       " 334        -0.25       5  -024Swollbc  \n",
       " 335         4.10       5  -024Swollbc  \n",
       " 336        -3.65       4  -024Swollbc  \n",
       " ..           ...     ...          ...  \n",
       " 427         1.98       2  -024Swollbc  \n",
       " 428         0.90       1  -024Swollbc  \n",
       " 429         0.22       1  -024Swollbc  \n",
       " 430         0.98       1  -024Swollbc  \n",
       " 431         0.18       2  -024Swollbc  \n",
       " \n",
       " [100 rows x 9 columns],\n",
       "                                                Comment Sentiment  \\\n",
       " 432  No one can create excitement like Kanye. Not e...  Positive   \n",
       " 433  I'm actually very excited for this album. Ther...  Positive   \n",
       " 434  Kanye is a beautiful  broken  artistic man. He...  Positive   \n",
       " 435  \"When Kanye West is focused on music  not too ...   Neutral   \n",
       " 436  We need this type of music. Music needs to go ...   Neutral   \n",
       " ..                                                 ...       ...   \n",
       " 495  Ye killed it! The spiritual mix in music is â€œh...  Positive   \n",
       " 496  An AMAZING EMOTIONAL ENCYCLOPEDIA OF SOME Of T...  Positive   \n",
       " 497  Facts or undeniable facts?...Kanye West needs ...   Neutral   \n",
       " 498  Hate him or love him he is the greatest artist...  Positive   \n",
       " 499  I don't get why I don't hear people put Kanye ...   Neutral   \n",
       " \n",
       "      Negative_percent  Neutral_percent  Positive_percent  Scaler_value  \\\n",
       " 432              0.84            11.93             87.24          0.86   \n",
       " 433              0.20             0.74             99.06          0.99   \n",
       " 434              1.76             9.46             88.78          0.87   \n",
       " 435             31.74            53.20             15.06         -0.17   \n",
       " 436              2.63            53.55             43.82          0.41   \n",
       " ..                ...              ...               ...           ...   \n",
       " 495             11.38            36.86             51.77          0.40   \n",
       " 496              0.16             2.34             97.51          0.97   \n",
       " 497             11.37            84.02              4.61         -0.07   \n",
       " 498              0.32             2.75             96.92          0.97   \n",
       " 499             34.14            48.88             16.98         -0.17   \n",
       " \n",
       "      weighted_SV  weight     video_id  \n",
       " 432         4.30       5  -0PZSxZuAXQ  \n",
       " 433         4.95       5  -0PZSxZuAXQ  \n",
       " 434         4.35       5  -0PZSxZuAXQ  \n",
       " 435        -0.85       5  -0PZSxZuAXQ  \n",
       " 436         2.05       5  -0PZSxZuAXQ  \n",
       " ..           ...     ...          ...  \n",
       " 495         0.80       2  -0PZSxZuAXQ  \n",
       " 496         0.97       1  -0PZSxZuAXQ  \n",
       " 497        -0.21       3  -0PZSxZuAXQ  \n",
       " 498         0.97       1  -0PZSxZuAXQ  \n",
       " 499        -0.17       1  -0PZSxZuAXQ  \n",
       " \n",
       " [68 rows x 9 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "for idx, df in enumerate(cut_dfs):\n",
    "    results = sentiment_score_comment(df)\n",
    "    results['video_id'] = df['video_id']\n",
    "    results_list.append(results)\n",
    "    print('I DID THIS VIDEO ', idx)\n",
    "    pandas_gbq.to_gbq(results, f'sentiment_scores.sentiment_up_to_{idx}', project_id=project_id)\n",
    "    print('AND NOW IT IS ON BIG QUERY', '\\n----------\\n')\n",
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa79ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative_percent</th>\n",
       "      <th>Neutral_percent</th>\n",
       "      <th>Positive_percent</th>\n",
       "      <th>Scaler_value</th>\n",
       "      <th>weighted_SV</th>\n",
       "      <th>weight</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respect to Dortmund fans must be sad losing him.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>33.80</td>\n",
       "      <td>50.22</td>\n",
       "      <td>15.98</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real talent  hope he doesn't turn into anoth...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>10.69</td>\n",
       "      <td>63.89</td>\n",
       "      <td>25.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wish him well in manchester united</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.78</td>\n",
       "      <td>87.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most talented players Bundesliga ha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.68</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>3</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a spell in the Bundesliga  Goodluck in th...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.56</td>\n",
       "      <td>96.26</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Has potential to be the next Ronaldo/messi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.86</td>\n",
       "      <td>35.08</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Sancho &lt;3  Thank you.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.30</td>\n",
       "      <td>92.49</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.68</td>\n",
       "      <td>2</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Welcome to Manchester United the theatre of dr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.92</td>\n",
       "      <td>92.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>I hope he became much stronger and healthier i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.31</td>\n",
       "      <td>97.56</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>All i can say is  good luck on your next desti...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.31</td>\n",
       "      <td>98.41</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment Sentiment  \\\n",
       "0     Respect to Dortmund fans must be sad losing him.   Neutral   \n",
       "1    A real talent  hope he doesn't turn into anoth...   Neutral   \n",
       "2                   wish him well in manchester united  Positive   \n",
       "3    One of the most talented players Bundesliga ha...  Positive   \n",
       "4    What a spell in the Bundesliga  Goodluck in th...  Positive   \n",
       "..                                                 ...       ...   \n",
       "170         Has potential to be the next Ronaldo/messi  Positive   \n",
       "171                              Sancho <3  Thank you.  Positive   \n",
       "172  Welcome to Manchester United the theatre of dr...  Positive   \n",
       "173  I hope he became much stronger and healthier i...  Positive   \n",
       "174  All i can say is  good luck on your next desti...  Positive   \n",
       "\n",
       "     Negative_percent  Neutral_percent  Positive_percent  Scaler_value  \\\n",
       "0               33.80            50.22             15.98         -0.18   \n",
       "1               10.69            63.89             25.42          0.15   \n",
       "2                0.31            11.78             87.91          0.88   \n",
       "3                0.22             1.68             98.10          0.98   \n",
       "4                0.18             3.56             96.26          0.96   \n",
       "..                ...              ...               ...           ...   \n",
       "170              0.86            35.08             64.07          0.63   \n",
       "171              0.21             7.30             92.49          0.92   \n",
       "172              0.17             6.92             92.91          0.93   \n",
       "173              0.14             2.31             97.56          0.97   \n",
       "174              0.28             1.31             98.41          0.98   \n",
       "\n",
       "     weighted_SV  weight     video_id  \n",
       "0          -0.90       5  --0bCF-iK2E  \n",
       "1           0.75       5  --0bCF-iK2E  \n",
       "2           4.40       5  --0bCF-iK2E  \n",
       "3           4.90       3  --0bCF-iK2E  \n",
       "4           4.80       4  --0bCF-iK2E  \n",
       "..           ...     ...          ...  \n",
       "170         0.63       1  --0bCF-iK2E  \n",
       "171         3.68       2  --0bCF-iK2E  \n",
       "172         1.86       2  --0bCF-iK2E  \n",
       "173         1.94       2  --0bCF-iK2E  \n",
       "174         0.98       1  --0bCF-iK2E  \n",
       "\n",
       "[175 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5983df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_score_df = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db71e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_df = pd.DataFrame(BIGdf.value_counts('video_id').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e69b91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_df['positivity_score'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b65c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>positivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--DKkzWVh-E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-024Swollbc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  positivity_score\n",
       "0  --0bCF-iK2E               NaN\n",
       "1  --DKkzWVh-E               NaN\n",
       "2  -024Swollbc               NaN\n",
       "3  -0PZSxZuAXQ               NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "902e3dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/tmp/ipykernel_16757/3420579272.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10699.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM AS FAR AS VIDEO  0  that is  0.0 %\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/tmp/ipykernel_16757/3420579272.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10131.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM AS FAR AS VIDEO  1  that is  25.0 %\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/tmp/ipykernel_16757/3420579272.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11491.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM AS FAR AS VIDEO  2  that is  50.0 %\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/tmp/ipykernel_16757/3420579272.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11008.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM AS FAR AS VIDEO  3  that is  75.0 %\n",
      "----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(cut_dfs):\n",
    "    \n",
    "    df['weight'] = df['likecount'].apply(making_weights)\n",
    "    \n",
    "    score_df = sentiment_score_comment(df)\n",
    "    \n",
    "    positivity_score = score_df['weighted_SV'].mean()\n",
    "    \n",
    "    IDs_df['positivity_score'][i] = positivity_score\n",
    "    \n",
    "    pandas_gbq.to_gbq(IDs_df, f'video_positivity_scores.positivity_up_to_{i}', project_id=project_id)\n",
    "    \n",
    "    print('I AM AS FAR AS VIDEO ', i, ' that is ', (i/len(cut_dfs))*100, '%\\n----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f3062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "results = sentiment_score_comment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942943f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(results_df):\n",
    "    IDs_df.to_csv('video_score.csv')\n",
    "    comment_score_df.to_csv('comment_score.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "506468e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(IDs_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99e6a1b7",
   "metadata": {},
   "source": [
    "# IDs_df.iloc[0].video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a9f71-6765-44c3-a41a-77622df77074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ecf98-ee22-4774-b437-c96fb7efc9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f6a41-74b1-48aa-ac64-9fbf13d25307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7326cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_id = IDs_df.iloc[0].video_id\n",
    "# IDs_df.to_csv(f'video_score{video_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65101122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs_df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
