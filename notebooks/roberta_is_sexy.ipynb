{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd0e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70199880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a36dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df2f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ.get('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb0e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGdf = pd.read_csv('comments/final_df_CLEAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6013edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGdf = BIGdf.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099a2364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likecount</th>\n",
       "      <th>date</th>\n",
       "      <th>replies</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Respect to Dortmund fans must be sad losing him.</td>\n",
       "      <td>Uh Idk</td>\n",
       "      <td>1932</td>\n",
       "      <td>2021-07-01T10:33:16Z</td>\n",
       "      <td>59</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A real talent  hope he doesn't turn into anoth...</td>\n",
       "      <td>7h35h96u9</td>\n",
       "      <td>617</td>\n",
       "      <td>2021-07-01T10:28:25Z</td>\n",
       "      <td>34</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wish him well in manchester united</td>\n",
       "      <td>Guncius</td>\n",
       "      <td>2583</td>\n",
       "      <td>2021-07-01T10:01:00Z</td>\n",
       "      <td>94</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>One of the most talented players Bundesliga ha...</td>\n",
       "      <td>Rishi Joe Sanu</td>\n",
       "      <td>57</td>\n",
       "      <td>2021-07-01T12:46:06Z</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What a spell in the Bundesliga  Goodluck in th...</td>\n",
       "      <td>H2KAL5859</td>\n",
       "      <td>66</td>\n",
       "      <td>2021-07-01T10:01:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>Nice job seth love the vids</td>\n",
       "      <td>Bossnoopdawg</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-03T15:00:49Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>When I clicked on the video I realised how tir...</td>\n",
       "      <td>Callum Musgrave</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04T00:14:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>i remember when the bike went upto $AU70 000 i...</td>\n",
       "      <td>tookken</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-03T21:24:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>Keep up the good work</td>\n",
       "      <td>Lisaferrypilatesfit</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-03T15:10:57Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>Love that bike!! Would love to do a future bui...</td>\n",
       "      <td>TrailTrialerMTB</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-03T15:07:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                            comment  \\\n",
       "0             0   Respect to Dortmund fans must be sad losing him.   \n",
       "1             1  A real talent  hope he doesn't turn into anoth...   \n",
       "2             2                 wish him well in manchester united   \n",
       "3             3  One of the most talented players Bundesliga ha...   \n",
       "4             4  What a spell in the Bundesliga  Goodluck in th...   \n",
       "..          ...                                                ...   \n",
       "395         395                        Nice job seth love the vids   \n",
       "396         396  When I clicked on the video I realised how tir...   \n",
       "397         397  i remember when the bike went upto $AU70 000 i...   \n",
       "398         398                              Keep up the good work   \n",
       "399         399  Love that bike!! Would love to do a future bui...   \n",
       "\n",
       "                  author  likecount                  date  replies  \\\n",
       "0                 Uh Idk       1932  2021-07-01T10:33:16Z       59   \n",
       "1              7h35h96u9        617  2021-07-01T10:28:25Z       34   \n",
       "2                Guncius       2583  2021-07-01T10:01:00Z       94   \n",
       "3         Rishi Joe Sanu         57  2021-07-01T12:46:06Z        1   \n",
       "4              H2KAL5859         66  2021-07-01T10:01:31Z        0   \n",
       "..                   ...        ...                   ...      ...   \n",
       "395         Bossnoopdawg          1  2021-03-03T15:00:49Z        0   \n",
       "396      Callum Musgrave          0  2021-03-04T00:14:31Z        0   \n",
       "397              tookken          0  2021-03-03T21:24:40Z        0   \n",
       "398  Lisaferrypilatesfit          1  2021-03-03T15:10:57Z        0   \n",
       "399      TrailTrialerMTB          0  2021-03-03T15:07:00Z        0   \n",
       "\n",
       "        video_id  \n",
       "0    --0bCF-iK2E  \n",
       "1    --0bCF-iK2E  \n",
       "2    --0bCF-iK2E  \n",
       "3    --0bCF-iK2E  \n",
       "4    --0bCF-iK2E  \n",
       "..           ...  \n",
       "395  -024Swollbc  \n",
       "396  -024Swollbc  \n",
       "397  -024Swollbc  \n",
       "398  -024Swollbc  \n",
       "399  -024Swollbc  \n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a8c1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      --0bCF-iK2E\n",
       "1      --0bCF-iK2E\n",
       "2      --0bCF-iK2E\n",
       "3      --0bCF-iK2E\n",
       "4      --0bCF-iK2E\n",
       "          ...     \n",
       "395    -024Swollbc\n",
       "396    -024Swollbc\n",
       "397    -024Swollbc\n",
       "398    -024Swollbc\n",
       "399    -024Swollbc\n",
       "Name: video_id, Length: 400, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e278ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['--0bCF-iK2E', '--DKkzWVh-E', '-024Swollbc'], dtype='object', name='video_id')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGdf.value_counts('video_id').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a281ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f6e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_weights(num):\n",
    "    '''This function makes weights for each comment based on its like count (num)'''\n",
    "    if num == 0:\n",
    "        return 1\n",
    "    elif num > 0 and num <= np.median(likes[:len(likes)//2]):\n",
    "        return 2\n",
    "    elif num > np.median(likes[:len(likes)//2]) and num <= np.median(likes):\n",
    "        return 3\n",
    "    elif num > np.median(likes) and num < np.median(likes[len(likes)//2:]):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9fef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cutter(df):\n",
    "    IDs_list = df.value_counts('video_id').keys()\n",
    "    cut_dfs = []\n",
    "    for i, video in enumerate(IDs_list):\n",
    "        cut_df = df[df['video_id'] == IDs_list[i]]\n",
    "        global likes\n",
    "        likes = sorted(list(cut_df[cut_df['likecount'] > 0]['likecount']))\n",
    "        cut_df['weight'] = cut_df['likecount'].apply(making_weights)\n",
    "        cut_dfs.append(cut_df)\n",
    "    return cut_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c2dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/2854793023.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cut_df['weight'] = cut_df['likecount'].apply(making_weights)\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/2854793023.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cut_df['weight'] = cut_df['likecount'].apply(making_weights)\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/2854793023.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cut_df['weight'] = cut_df['likecount'].apply(making_weights)\n"
     ]
    }
   ],
   "source": [
    "cut_dfs = df_cutter(BIGdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f28c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_comment(df):\n",
    "\n",
    "    '''This function predicts the sentiment score of each youtube video!'''\n",
    "    \n",
    "    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Lists to store the sentiment analysis results\n",
    "    sentiment_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    positive_list = []\n",
    "    scalar_value_list = []\n",
    "    weighted_SV = []\n",
    "    weight = list(df['likecount'].apply(making_weights))\n",
    "\n",
    "    # Iterate over the comments in the DataFrame\n",
    "    for i, text in enumerate(df['comment']):\n",
    "        \n",
    "        # Tokenization, Sentiment Prediction, and Interpretation\n",
    "        tokens = tokenizer.encode_plus(text, add_special_tokens=True, padding='longest', truncation=True, max_length=512, return_tensors='tf')\n",
    "        outputs = model(tokens.input_ids)\n",
    "        logits = outputs.logits\n",
    "        prediction = np.array(tf.nn.softmax(logits)[0])\n",
    "        predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "        sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "        predicted_sentiment = sentiment_labels[predicted_class]\n",
    "\n",
    "        # Append the sentiment analysis results to the respective lists\n",
    "        sentiment_list.append(predicted_sentiment)\n",
    "        negative_list.append(round(prediction[0]*100, 2))\n",
    "        neutral_list.append(round(prediction[1]*100, 2))\n",
    "        positive_list.append(round(prediction[2]*100, 2))\n",
    "        scalar_value_val = round((prediction[0])*-1+(prediction[2]*1),2)\n",
    "        scalar_value_list.append(scalar_value_val)\n",
    "        weighted_SV.append(df['weight'].iloc[i] * scalar_value_val)\n",
    "\n",
    "\n",
    "    # Create a new DataFrame with the sentiment analysis results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Comment': df['comment'],\n",
    "        'Sentiment': sentiment_list,\n",
    "        'Negative (%)': negative_list,\n",
    "        'Neutral (%)': neutral_list,\n",
    "        'Positive (%)': positive_list,\n",
    "        'Scaler_value': scalar_value_list,\n",
    "        'weighted_SV': weighted_SV,\n",
    "        'weight': weight\n",
    "    })\n",
    "\n",
    "    # Return the new DataFrame\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00284ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                               Comment Sentiment  \\\n",
       " 0     Respect to Dortmund fans must be sad losing him.   Neutral   \n",
       " 1    A real talent  hope he doesn't turn into anoth...   Neutral   \n",
       " 2                   wish him well in manchester united  Positive   \n",
       " 3    One of the most talented players Bundesliga ha...  Positive   \n",
       " 4    What a spell in the Bundesliga  Goodluck in th...  Positive   \n",
       " ..                                                 ...       ...   \n",
       " 170         Has potential to be the next Ronaldo/messi  Positive   \n",
       " 171                              Sancho <3  Thank you.  Positive   \n",
       " 172  Welcome to Manchester United the theatre of dr...  Positive   \n",
       " 173  I hope he became much stronger and healthier i...  Positive   \n",
       " 174  All i can say is  good luck on your next desti...  Positive   \n",
       " \n",
       "      Negative (%)  Neutral (%)  Positive (%)  Scaler_value  weighted_SV  \\\n",
       " 0           33.80        50.22         15.98         -0.18        -0.90   \n",
       " 1           10.69        63.89         25.42          0.15         0.75   \n",
       " 2            0.31        11.78         87.91          0.88         4.40   \n",
       " 3            0.22         1.68         98.10          0.98         4.90   \n",
       " 4            0.18         3.56         96.26          0.96         4.80   \n",
       " ..            ...          ...           ...           ...          ...   \n",
       " 170          0.86        35.08         64.07          0.63         0.63   \n",
       " 171          0.21         7.30         92.49          0.92         3.68   \n",
       " 172          0.17         6.92         92.91          0.93         1.86   \n",
       " 173          0.14         2.31         97.56          0.97         1.94   \n",
       " 174          0.28         1.31         98.41          0.98         0.98   \n",
       " \n",
       "      weight     video_id  \n",
       " 0         5  --0bCF-iK2E  \n",
       " 1         5  --0bCF-iK2E  \n",
       " 2         5  --0bCF-iK2E  \n",
       " 3         5  --0bCF-iK2E  \n",
       " 4         5  --0bCF-iK2E  \n",
       " ..      ...          ...  \n",
       " 170       1  --0bCF-iK2E  \n",
       " 171       4  --0bCF-iK2E  \n",
       " 172       2  --0bCF-iK2E  \n",
       " 173       2  --0bCF-iK2E  \n",
       " 174       1  --0bCF-iK2E  \n",
       " \n",
       " [175 rows x 9 columns],\n",
       "                                                Comment Sentiment  \\\n",
       " 175  ðŸš§ Keep up with all my projects here: https://p...  Positive   \n",
       " 176  Your mechanically stabilized earth video inspi...  Positive   \n",
       " 177  As a professional landscapers who has built qu...   Neutral   \n",
       " 178  I love that heâ€™s a civil engineer and his name...  Positive   \n",
       " 179  Thanks to videos like these I massively overde...  Positive   \n",
       " ..                                                 ...       ...   \n",
       " 327  One of the most deadly things on construction ...  Negative   \n",
       " 328  I love watching your videos  there's always so...  Positive   \n",
       " 329  As an old renovator and retention wall builder...   Neutral   \n",
       " 330  Great video  but you need a 2:1 or 4:1 audio c...   Neutral   \n",
       " 331  Yet another excellent video about engineering....  Positive   \n",
       " \n",
       "      Negative (%)  Neutral (%)  Positive (%)  Scaler_value  weighted_SV  \\\n",
       " 175          0.29        30.31         69.40          0.69         3.45   \n",
       " 176          0.60        35.77         63.63          0.63         3.15   \n",
       " 177          5.11        69.74         25.16          0.20         1.00   \n",
       " 178          0.22         1.97         97.81          0.98         4.90   \n",
       " 179          0.58        11.11         88.31          0.88         3.52   \n",
       " ..            ...          ...           ...           ...          ...   \n",
       " 327         93.27         6.16          0.57         -0.93        -3.72   \n",
       " 328          0.19         1.07         98.73          0.99         0.99   \n",
       " 329         17.92        62.37         19.71          0.02         0.02   \n",
       " 330         31.16        49.34         19.49         -0.12        -0.12   \n",
       " 331          0.47         5.78         93.76          0.93         2.79   \n",
       " \n",
       "      weight     video_id  \n",
       " 175       5  --DKkzWVh-E  \n",
       " 176       5  --DKkzWVh-E  \n",
       " 177       5  --DKkzWVh-E  \n",
       " 178       5  --DKkzWVh-E  \n",
       " 179       5  --DKkzWVh-E  \n",
       " ..      ...          ...  \n",
       " 327       4  --DKkzWVh-E  \n",
       " 328       1  --DKkzWVh-E  \n",
       " 329       1  --DKkzWVh-E  \n",
       " 330       1  --DKkzWVh-E  \n",
       " 331       4  --DKkzWVh-E  \n",
       " \n",
       " [157 rows x 9 columns],\n",
       "                                                Comment Sentiment  \\\n",
       " 332  This man is great. He gives his daughter priva...  Positive   \n",
       " 333  Man is a genius  going to get to write that of...  Positive   \n",
       " 334       This is obviously more important than school   Neutral   \n",
       " 335  Jared seems like a great person. For sure gonn...  Positive   \n",
       " 336  The dislikes are the people who didnâ€™t get the...  Negative   \n",
       " ..                                                 ...       ...   \n",
       " 395                        Nice job seth love the vids  Positive   \n",
       " 396  When I clicked on the video I realised how tir...   Neutral   \n",
       " 397  i remember when the bike went upto $AU70 000 i...   Neutral   \n",
       " 398                              Keep up the good work  Positive   \n",
       " 399  Love that bike!! Would love to do a future bui...  Positive   \n",
       " \n",
       "      Negative (%)  Neutral (%)  Positive (%)  Scaler_value  weighted_SV  \\\n",
       " 332          0.23         2.03         97.75          0.98         4.90   \n",
       " 333          0.47        10.17         89.36          0.89         4.45   \n",
       " 334         28.34        48.12         23.54         -0.05        -0.25   \n",
       " 335          3.37        11.56         85.07          0.82         4.10   \n",
       " 336         74.52        23.48          2.00         -0.73        -3.65   \n",
       " ..            ...          ...           ...           ...          ...   \n",
       " 395          0.20         1.18         98.62          0.98         1.96   \n",
       " 396         29.10        60.33         10.57         -0.19        -0.19   \n",
       " 397         31.35        61.29          7.36         -0.24        -0.24   \n",
       " 398          0.43         6.00         93.57          0.93         1.86   \n",
       " 399          0.11         1.37         98.52          0.98         0.98   \n",
       " \n",
       "      weight     video_id  \n",
       " 332       5  -024Swollbc  \n",
       " 333       5  -024Swollbc  \n",
       " 334       5  -024Swollbc  \n",
       " 335       5  -024Swollbc  \n",
       " 336       5  -024Swollbc  \n",
       " ..      ...          ...  \n",
       " 395       2  -024Swollbc  \n",
       " 396       1  -024Swollbc  \n",
       " 397       1  -024Swollbc  \n",
       " 398       2  -024Swollbc  \n",
       " 399       1  -024Swollbc  \n",
       " \n",
       " [68 rows x 9 columns]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "for df in cut_dfs:\n",
    "    results = sentiment_score_comment(df)\n",
    "    results['video_id'] = df['video_id']\n",
    "    results_list.append(results)\n",
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa79ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negative (%)</th>\n",
       "      <th>Neutral (%)</th>\n",
       "      <th>Positive (%)</th>\n",
       "      <th>Scaler_value</th>\n",
       "      <th>weighted_SV</th>\n",
       "      <th>weight</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respect to Dortmund fans must be sad losing him.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>33.80</td>\n",
       "      <td>50.22</td>\n",
       "      <td>15.98</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real talent  hope he doesn't turn into anoth...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>10.69</td>\n",
       "      <td>63.89</td>\n",
       "      <td>25.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wish him well in manchester united</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.78</td>\n",
       "      <td>87.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most talented players Bundesliga ha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.68</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a spell in the Bundesliga  Goodluck in th...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.56</td>\n",
       "      <td>96.26</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Has potential to be the next Ronaldo/messi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.86</td>\n",
       "      <td>35.08</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Sancho &lt;3  Thank you.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.30</td>\n",
       "      <td>92.49</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Welcome to Manchester United the theatre of dr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.92</td>\n",
       "      <td>92.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>I hope he became much stronger and healthier i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.31</td>\n",
       "      <td>97.56</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>All i can say is  good luck on your next desti...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.31</td>\n",
       "      <td>98.41</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment Sentiment  \\\n",
       "0     Respect to Dortmund fans must be sad losing him.   Neutral   \n",
       "1    A real talent  hope he doesn't turn into anoth...   Neutral   \n",
       "2                   wish him well in manchester united  Positive   \n",
       "3    One of the most talented players Bundesliga ha...  Positive   \n",
       "4    What a spell in the Bundesliga  Goodluck in th...  Positive   \n",
       "..                                                 ...       ...   \n",
       "170         Has potential to be the next Ronaldo/messi  Positive   \n",
       "171                              Sancho <3  Thank you.  Positive   \n",
       "172  Welcome to Manchester United the theatre of dr...  Positive   \n",
       "173  I hope he became much stronger and healthier i...  Positive   \n",
       "174  All i can say is  good luck on your next desti...  Positive   \n",
       "\n",
       "     Negative (%)  Neutral (%)  Positive (%)  Scaler_value  weighted_SV  \\\n",
       "0           33.80        50.22         15.98         -0.18        -0.90   \n",
       "1           10.69        63.89         25.42          0.15         0.75   \n",
       "2            0.31        11.78         87.91          0.88         4.40   \n",
       "3            0.22         1.68         98.10          0.98         4.90   \n",
       "4            0.18         3.56         96.26          0.96         4.80   \n",
       "..            ...          ...           ...           ...          ...   \n",
       "170          0.86        35.08         64.07          0.63         0.63   \n",
       "171          0.21         7.30         92.49          0.92         3.68   \n",
       "172          0.17         6.92         92.91          0.93         1.86   \n",
       "173          0.14         2.31         97.56          0.97         1.94   \n",
       "174          0.28         1.31         98.41          0.98         0.98   \n",
       "\n",
       "     weight     video_id  \n",
       "0         5  --0bCF-iK2E  \n",
       "1         5  --0bCF-iK2E  \n",
       "2         5  --0bCF-iK2E  \n",
       "3         5  --0bCF-iK2E  \n",
       "4         5  --0bCF-iK2E  \n",
       "..      ...          ...  \n",
       "170       1  --0bCF-iK2E  \n",
       "171       4  --0bCF-iK2E  \n",
       "172       2  --0bCF-iK2E  \n",
       "173       2  --0bCF-iK2E  \n",
       "174       1  --0bCF-iK2E  \n",
       "\n",
       "[175 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5983df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_score_df = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db71e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_df = pd.DataFrame(BIGdf.value_counts('video_id').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e69b91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_df['positivity_score'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b65c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>positivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--DKkzWVh-E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-024Swollbc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  positivity_score\n",
       "0  --0bCF-iK2E               NaN\n",
       "1  --DKkzWVh-E               NaN\n",
       "2  -024Swollbc               NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "902e3dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weight'] = df['likecount'].apply(making_weights)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weight'] = df['likecount'].apply(making_weights)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weight'] = df['likecount'].apply(making_weights)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/var/folders/lp/kbcy9lh91kjc0lpdp8ydq1wr0000gn/T/ipykernel_78382/4242844407.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IDs_df['positivity_score'][i] = positivity_score\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(cut_dfs):\n",
    "    \n",
    "    df['weight'] = df['likecount'].apply(making_weights)\n",
    "    \n",
    "    score_df = sentiment_score_comment(df)\n",
    "    \n",
    "    positivity_score = score_df['weighted_SV'].mean()\n",
    "    \n",
    "    IDs_df['positivity_score'][i] = positivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5f3062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "results = sentiment_score_comment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "942943f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(results_df):\n",
    "    IDs_df.to_csv('video_score.csv')\n",
    "    comment_score_df.to_csv('comment_score.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "506468e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(IDs_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99e6a1b7",
   "metadata": {},
   "source": [
    "# IDs_df.iloc[0].video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7326cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_id = IDs_df.iloc[0].video_id\n",
    "# IDs_df.to_csv(f'video_score{video_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65101122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
