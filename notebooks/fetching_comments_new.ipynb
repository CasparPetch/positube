{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7ffbcf",
   "metadata": {},
   "source": [
    "# Grabbing comments"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 73,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "5f1d6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = 0"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "1f01dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "ee3cf006",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "ee3cf006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    --0bCF-iK2E\n",
       "1    --14w5SOEUs\n",
       "2    --40TEbZ9Is\n",
       "3    --4tfbSyYDE\n",
       "4    --DKkzWVh-E\n",
       "5    --FmExEAsM8\n",
       "6    --tbUe0JRc8\n",
       "7    -024Swollbc\n",
       "8    -0PZSxZuAXQ\n",
       "9    -0QSEZIqVWc\n",
       "Name: video_id, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "source": [
    "df = pd.read_csv(\"IDs.csv\")[\"video_id\"][0:10]\n",
    "df#"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "5d64b7c1",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 3,
   "id": "5d64b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--14w5SOEUs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--40TEbZ9Is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--4tfbSyYDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--DKkzWVh-E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--FmExEAsM8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--tbUe0JRc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-024Swollbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0QSEZIqVWc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id\n",
       "0  --0bCF-iK2E\n",
       "1  --14w5SOEUs\n",
       "2  --40TEbZ9Is\n",
       "3  --4tfbSyYDE\n",
       "4  --DKkzWVh-E\n",
       "5  --FmExEAsM8\n",
       "6  --tbUe0JRc8\n",
       "7  -024Swollbc\n",
       "8  -0PZSxZuAXQ\n",
       "9  -0QSEZIqVWc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "source": [
    "comments_df = pd.DataFrame(df)\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "e3e5b471",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "id": "e3e5b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/casparpetch/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('words')\n",
    "\n",
    "def clean_and_filter(df):\n",
    "    def remove_newline(text):\n",
    "        text = text.replace('\\n', '') \n",
    "        return text\n",
    "\n",
    "    def remove_punctuation(text):\n",
    "        for punctuation in string.punctuation: \n",
    "            text = text.replace(punctuation, '') \n",
    "        return text\n",
    "\n",
    "    def lowercase (text): \n",
    "        lowercased = text.lower() \n",
    "        return lowercased\n",
    "\n",
    "    df['comment_clean'] = df.comment.apply(remove_newline)\n",
    "    df['comment_clean'] = df.comment_clean.apply(remove_punctuation)\n",
    "    df['comment_clean'] = df.comment_clean.apply(lowercase)\n",
    "    \n",
    "    english_words = set(words.words())\n",
    "    def is_english(text):\n",
    "        words_in_comment = word_tokenize(text)\n",
    "        num_words_in_comment = len(words_in_comment)\n",
    "        num_english_words_in_comment = 0\n",
    "        for word in words_in_comment:\n",
    "            if word in english_words:\n",
    "                num_english_words_in_comment += 1\n",
    "        english = False\n",
    "        if num_english_words_in_comment/num_words_in_comment >= 0.3:\n",
    "            english = True\n",
    "        return english\n",
    "    \n",
    "    def english_only(df):\n",
    "        df['english'] = df['comment_clean'].apply(is_english)\n",
    "        return df\n",
    "\n",
    "    df = english_only(df)\n",
    "    \n",
    "    def remove_non_english_symbols(text):\n",
    "        english_pattern = re.compile(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]')\n",
    "        cleaned_text = re.sub(english_pattern, '', text)\n",
    "        return cleaned_text\n",
    "    \n",
    "    \n",
    "    df['comment_clean'] = df.comment_clean.apply(remove_non_english_symbols)\n",
    "    \n",
    "    return df[df[\"english\"] == True]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "6f6d717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {\n",
    "    \"1\":\"Film & Animation\",\n",
    "    \"2\":\"Autos & Vehicles\",\n",
    "    \"10\":\"Music\",\n",
    "    \"15\":\"Pets & Animals\",\n",
    "    \"17\":\"Sports\",\n",
    "    \"18\":\"Short Movies\",\n",
    "    \"19\":\"Travel & Events\",\n",
    "    \"20\":\"Gaming\",\n",
    "    \"21\":\"Videoblogging\",\n",
    "    \"22\":\"People & Blogs\",\n",
    "    \"23\":\"Comedy\",\n",
    "    \"24\":\"Entertainment\",\n",
    "    \"25\":\"News & Politics\",\n",
    "    \"26\":\"Howto & Style\",\n",
    "    \"27\":\"Education\",\n",
    "    \"28\":\"Science & Technology\",\n",
    "    \"29\":\"Nonprofits & Activism\",\n",
    "    \"30\":\"Movies\",\n",
    "    \"31\":\"Anime/Animation\",\n",
    "    \"32\":\"Action/Adventure\",\n",
    "    \"33\":\"Classics\",\n",
    "    \"34\":\"Comedy\",\n",
    "    \"35\":\"Documentary\",\n",
    "    \"36\":\"Drama\",\n",
    "    \"37\":\"Family\",\n",
    "    \"38\":\"Foreign\",\n",
    "    \"39\":\"Horror\",\n",
    "    \"40\":\"Sci-Fi/Fantasy\",\n",
    "    \"41\":\"Thriller\",\n",
    "    \"42\":\"Shorts\",\n",
    "    \"43\":\"Shows\",\n",
    "    \"44\":\"Trailers\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "5bcd289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_key_index = 0\n",
    "current_key_calls = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 85,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "348e4986",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# comment\n",
    "# def fetch_comments_relevance(video_id, api_key):\n",
    "#     url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={video_id}&key={api_key}&maxResults=100&order=relevance\"\n",
    "#     comments = []\n",
    "#     nextPageToken = None\n",
    "#     iter_number = 0\n",
    "#     token_count = 0\n",
    "#     while len(comments) < 100:\n",
    "#         print(f\"Tokens used: {token_count}\")\n",
    "        \n",
    "#         if nextPageToken:\n",
    "#             url += f\"&pageToken={nextPageToken}\"\n",
    "        \n",
    "#         response = requests.get(url)\n",
    "#         token_count += 1\n",
    "#         data = response.json()\n",
    "        \n",
    "#         error = data.get(\"error\", False)\n",
    "#         if error:\n",
    "#             return [\"\"]\n",
    "        \n",
    "#         for item in data.get(\"items\", []):\n",
    "#             if item:\n",
    "#                 comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"]\n",
    "#                 author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"]\n",
    "#                 likecount = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"]\n",
    "#                 date = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"]\n",
    "#                 replies = item[\"snippet\"][\"totalReplyCount\"]\n",
    "#                 dict_ = {\"comment\": comment, \"author\": author, \"likecount\": likecount, \"date\": date, \"replies\": replies}\n",
    "\n",
    "#                 if comment is not None:\n",
    "#                     cleaned_comment = clean_and_filter(pd.DataFrame([comment],columns=[\"comment\"]))\n",
    "#                     if not cleaned_comment.empty:\n",
    "#                         if cleaned_comment[\"english\"][0] == True:\n",
    "#                             dict_[\"comment_clean\"] = cleaned_comment[\"comment_clean\"]\n",
    "#                             comments.append(dict_)\n",
    "#         nextPageToken = data.get(\"nextPageToken\", None)\n",
    "#         if not nextPageToken or iter_number >= 4:\n",
    "#             break\n",
    "#         if iter_number == 0:\n",
    "#             if len(comments) < 25:\n",
    "#                 break\n",
    "#         iter_number += 1\n",
    "    \n",
    "#     return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "API_KEYS = [\n",
    "    os.getenv('API_KEY'),\n",
    "    os.getenv('API_KEY_1'),\n",
    "    os.getenv('API_KEY_2'),\n",
    "    os.getenv('API_KEY_3'),\n",
    "    os.getenv('API_KEY_4'),\n",
    "    os.getenv('API_KEY_5'),\n",
    "    os.getenv('API_KEY_6'),\n",
    "    os.getenv('API_KEY_7'),\n",
    "    os.getenv('API_KEY_8'),\n",
    "    os.getenv('API_KEY_9'),\n",
    "    os.getenv('API_KEY_10'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d05f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_comments_relevance(video_id, API_KEYS):\n",
    "    max_results = 100\n",
    "    order = \"relevance\"\n",
    "    \n",
=======
    "def fetch_comments_relevance(video_id, api_key):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={video_id}&key={api_key}&maxResults=100&order=relevance\"\n",
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
    "    comments = []\n",
    "    nextPageToken = None\n",
    "    iter_number = 0\n",
    "    token_count = 0\n",
    "    while len(comments) < 100:\n",
    "        print(f\"Tokens used: {token_count}\")\n",
    "        \n",
    "        if nextPageToken:\n",
    "            url += f\"&pageToken={nextPageToken}\"\n",
    "        \n",
    "        response = requests.get(url)\n",
<<<<<<< HEAD
    "        print('RESPONSE: ', response)\n",
    "        print('RESPONSE STATUS: ', response.status_code)\n",
    "        print('OK?: ', response.ok)\n",
    "        if (response.status_code == 403 or response.status_code == 400) and idx < len(API_KEYS):\n",
    "            idx += 1 \n",
    "#             print (f\"I'm using this API key: {API_KEYS[idx]}\")\n",
    "            print (f\"I was at this video id: {video_id}\")\n",
    "            url = f\"{url_base}?part=snippet&videoId={video_id}&key={API_KEYS[idx]}&maxResults=100&order=relevance\"\n",
    "            if nextPageToken:\n",
    "                url += f\"&pageToken={nextPageToken}\"\n",
    "            response = requests.get(url)\n",
    "\n",
    "        if idx >= len(API_KEYS):\n",
    "            print(\"I've run out of API keys\")\n",
    "            break\n",
    "\n",
=======
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
    "        token_count += 1\n",
    "        data = response.json()\n",
    "        \n",
    "        error = data.get(\"error\", False)\n",
    "        if error:\n",
    "            return [\"\"]\n",
    "        \n",
    "        for item in data.get(\"items\", []):\n",
    "            if item:\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"]\n",
    "                author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"]\n",
    "                likecount = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"]\n",
    "                date = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"]\n",
    "                replies = item[\"snippet\"][\"totalReplyCount\"]\n",
    "                dict_ = {\"comment\": comment, \"author\": author, \"likecount\": likecount, \"date\": date, \"replies\": replies}\n",
    "\n",
    "                if comment is not None:\n",
    "                    cleaned_comment = clean_and_filter(pd.DataFrame([comment],columns=[\"comment\"]))\n",
    "                    if not cleaned_comment.empty:\n",
    "                        if cleaned_comment[\"english\"][0] == True:\n",
    "                            dict_[\"comment_clean\"] = cleaned_comment[\"comment_clean\"]\n",
    "                            comments.append(dict_)\n",
    "        nextPageToken = data.get(\"nextPageToken\", None)\n",
    "        if not nextPageToken or iter_number >= 4:\n",
    "            break\n",
    "        if iter_number == 0:\n",
    "            if len(comments) < 25:\n",
    "                break\n",
    "        iter_number += 1\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "8f5c7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stats(video_id, api_key):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videos?part=statistics&id={video_id}&key={api_key}\"\n",
    "    \n",
<<<<<<< HEAD
    "    for v_i, video_id in enumerate(VIDEO_IDS):\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/videos?part=statistics&id={video_id}&key={API_KEYS[idx]}\"\n",
    "        response = requests.get(url)\n",
    "        print('RESPONSE: ', response)\n",
    "        print('RESPONSE STATUS: ', response.status_code)\n",
    "        print('OK?: ', response.ok)\n",
    "\n",
    "        if (response.status_code == 403 or response.status_code == 400) :\n",
    "#             print (f\"I was using this API key: {API_KEYS[idx]}\")\n",
    "            print (f\"I was at this video id: {video_id}\")\n",
    "            results.setdefault(API_KEYS[idx], {})\n",
    "            results[API_KEYS[idx]][video_id] =  {'FINAL VIDEO'}\n",
    "            if idx + 1 < len(API_KEYS):\n",
    "                idx += 1\n",
    "                api_key = API_KEYS[idx]\n",
    "            else:\n",
    "                print('I am now out of API KEYS - these are the remaining videos:')\n",
    "                print(VIDEO_IDS[v_i:])\n",
    "                return results, VIDEO_IDS[v_i:]\n",
    "        \n",
    "\n",
    "        else:\n",
    "            data = response.json()\n",
    "            error = data.get(\"error\",False)\n",
    "            if not error:\n",
    "                data = data.get(\"items\",False)\n",
    "                if data:\n",
    "                    views = data[0][\"statistics\"][\"viewCount\"]\n",
    "                    likes = data[0][\"statistics\"][\"likeCount\"]\n",
    "                    comments = data[0][\"statistics\"][\"commentCount\"]\n",
    "                    dict_ = {\"views\":[views], \"likes\":[likes], \"comments\":[comments]}\n",
    "                    results.setdefault(API_KEYS[idx], {})\n",
    "                    results[API_KEYS[idx]][video_id] =  dict_\n",
    "                    \n",
    "    return results"
=======
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    error = data.get(\"error\",False)\n",
    "    if not error:\n",
    "        data = data.get(\"items\",False)\n",
    "        if data:\n",
    "            views = data[0][\"statistics\"][\"viewCount\"]\n",
    "            likes = data[0][\"statistics\"][\"likeCount\"]\n",
    "            comments = data[0][\"statistics\"][\"commentCount\"]\n",
    "            dict_ = {\"views\":[views], \"likes\":[likes], \"comments\":[comments]}\n",
    "            return dict_\n",
    "        return {}\n",
    "    else:\n",
    "        return {}"
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "6ffa8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(video_id, api_key):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={api_key}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
<<<<<<< HEAD
    "    print('RESPONSE: ', response)\n",
    "    print('RESPONSE STATUS: ', response.status_code)\n",
    "    print('OK?: ', response.ok)\n",
    "    \n",
    "    if (response.status_code == 403 or response.status_code == 400) and idx < len(API_KEYS):\n",
    "        idx += 1 \n",
    "#         print (f\"I'm using this API key: {API_KEYS[idx]}\")\n",
    "        print (f\"I was at this video id: {video_id}\")\n",
    "        url = f\"{url_base}?part=snippet&videoId={video_id}&key={API_KEYS[idx]}&maxResults=100&order=relevance\"\n",
    "        response = requests.get(url)\n",
    "        \n",
=======
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
    "    data = response.json()\n",
    "    error = data.get(\"error\",False)\n",
    "    if not error:\n",
    "        data = data.get(\"items\",False)\n",
    "        if data:\n",
    "            date = data[0][\"snippet\"][\"publishedAt\"]\n",
    "            channel_id = data[0][\"snippet\"][\"channelId\"]\n",
    "            title = data[0][\"snippet\"][\"title\"]\n",
    "            description = data[0][\"snippet\"][\"description\"]\n",
    "            channel_title = data[0][\"snippet\"][\"channelTitle\"]\n",
    "            tags = data[0][\"snippet\"].get(\"tags\",[\"\"])\n",
    "            genre = genre_dict[data[0][\"snippet\"][\"categoryId\"]]\n",
    "            language = data[0][\"snippet\"].get(\"defaultAudioLanguage\",\"\")\n",
    "            dict_ = {\"date\":date, \"channel_id\":channel_id, \"title\":title, \"description\":description, \"channel_title\":channel_title, \"tags\":[tags], \"genre\":genre, \"language\":language}\n",
    "            return dict_\n",
    "        return {}\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
   "id": "c85c4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "API_KEY = os.environ.get('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "65465fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_info(video_id, api_key):\n",
    "    details = pd.DataFrame(fetch_details(video_id, api_key))\n",
    "    print(details[\"language\"][0])\n",
    "    if details[\"language\"][0] in (\"en\", \"en-GB\", \"en-US\"):\n",
    "        comments_relevance = pd.DataFrame(fetch_comments_relevance(video_id, api_key))\n",
    "        stats = pd.DataFrame(fetch_stats(video_id, api_key))\n",
    "        info_all = pd.concat([stats,details],axis=1)\n",
    "        return comments_relevance, info_all"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "a93b8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_IDS = [\"--0bCF-iK2E\", \"uL6AZ4fiJeo\", 'uzlZm_ROi4c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272ef33",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 32,
   "id": "0272ef33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'views': ['1405682'], 'likes': ['24766'], 'comments': ['1437']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "source": [
    "dict_ = fetch_stats(\"--0bCF-iK2E\", API_KEY)\n",
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a2d2087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'views': ['1405682'], 'likes': ['24766'], 'comments': ['1437']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6f3e92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405682</td>\n",
       "      <td>24766</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     views  likes comments\n",
       "0  1405682  24766     1437"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9624274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokens: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "382ffce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--0bCF-iK2E\n",
      "en\n",
      "Tokens used: 0\n",
      "Tokens used: 1\n",
      "--14w5SOEUs\n",
      "\n",
      "--40TEbZ9Is\n",
      "\n",
      "--4tfbSyYDE\n",
      "en\n",
      "Tokens used: 0\n",
      "--DKkzWVh-E\n",
      "en\n",
      "Tokens used: 0\n",
      "--FmExEAsM8\n",
      "ko\n",
      "--tbUe0JRc8\n",
      "fr\n",
      "-024Swollbc\n",
      "en-US\n",
      "Tokens used: 0\n",
      "-0PZSxZuAXQ\n",
      "en\n",
      "Tokens used: 0\n",
      "-0QSEZIqVWc\n",
      "en\n",
      "Tokens used: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likecount</th>\n",
       "      <th>date</th>\n",
       "      <th>replies</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respect to Dortmund fans,must be sad losing him.</td>\n",
       "      <td>Uh Idk</td>\n",
       "      <td>1932</td>\n",
       "      <td>2021-07-01T10:33:16Z</td>\n",
       "      <td>59</td>\n",
       "      <td>0    respect to dortmund fansmust be sad losin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real talent, hope he doesn't turn into anoth...</td>\n",
       "      <td>7h35h96u9</td>\n",
       "      <td>617</td>\n",
       "      <td>2021-07-01T10:28:25Z</td>\n",
       "      <td>34</td>\n",
       "      <td>0    a real talent hope he doesnt turn into an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's so heartbreaking look at Sancho playing f...</td>\n",
       "      <td>Dushan Sinx</td>\n",
       "      <td>31</td>\n",
       "      <td>2022-09-03T06:30:08Z</td>\n",
       "      <td>3</td>\n",
       "      <td>0    its so heartbreaking look at sancho playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wish him well in manchester united</td>\n",
       "      <td>Guncius</td>\n",
       "      <td>2582</td>\n",
       "      <td>2021-07-01T10:01:00Z</td>\n",
       "      <td>94</td>\n",
       "      <td>0    wish him well in manchester united\n",
       "Name: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the most talented players Bundesliga ha...</td>\n",
       "      <td>Rishi Joe Sanu</td>\n",
       "      <td>57</td>\n",
       "      <td>2021-07-01T12:46:06Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0    one of the most talented players bundesli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Has potential to be the next Ronaldo/messi</td>\n",
       "      <td>Big Dee</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-19T00:03:49Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    has potential to be the next ronaldomessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Sancho &lt;3 \\nThank you.</td>\n",
       "      <td>VƒÉn T·∫•n Nguy·ªÖn</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-07-01T10:23:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    sancho 3 thank you\n",
       "Name: comment_clean, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Welcome to Manchester United the theatre of dr...</td>\n",
       "      <td>Goodfella007</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-02T08:54:34Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    welcome to manchester united the theatre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>I hope he became much stronger and healthier i...</td>\n",
       "      <td>youngvinzx</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-02T06:59:41Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    i hope he became much stronger and health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>All i can say is, good luck on your next desti...</td>\n",
       "      <td>MIKE JOKER 14</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01T16:59:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    all i can say is good luck on your next d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment          author  \\\n",
       "0     Respect to Dortmund fans,must be sad losing him.          Uh Idk   \n",
       "1    A real talent, hope he doesn't turn into anoth...       7h35h96u9   \n",
       "2    It's so heartbreaking look at Sancho playing f...     Dushan Sinx   \n",
       "3                   wish him well in manchester united         Guncius   \n",
       "4    One of the most talented players Bundesliga ha...  Rishi Joe Sanu   \n",
       "..                                                 ...             ...   \n",
       "190         Has potential to be the next Ronaldo/messi         Big Dee   \n",
       "191                             Sancho <3 \\nThank you.  VƒÉn T·∫•n Nguy·ªÖn   \n",
       "192  Welcome to Manchester United the theatre of dr...    Goodfella007   \n",
       "193  I hope he became much stronger and healthier i...      youngvinzx   \n",
       "194  All i can say is, good luck on your next desti...   MIKE JOKER 14   \n",
       "\n",
       "     likecount                  date  replies  \\\n",
       "0         1932  2021-07-01T10:33:16Z       59   \n",
       "1          617  2021-07-01T10:28:25Z       34   \n",
       "2           31  2022-09-03T06:30:08Z        3   \n",
       "3         2582  2021-07-01T10:01:00Z       94   \n",
       "4           57  2021-07-01T12:46:06Z        1   \n",
       "..         ...                   ...      ...   \n",
       "190          0  2021-07-19T00:03:49Z        0   \n",
       "191          6  2021-07-01T10:23:39Z        0   \n",
       "192          1  2021-07-02T08:54:34Z        0   \n",
       "193          1  2021-07-02T06:59:41Z        0   \n",
       "194          0  2021-07-01T16:59:40Z        0   \n",
       "\n",
       "                                         comment_clean  \n",
       "0    0    respect to dortmund fansmust be sad losin...  \n",
       "1    0    a real talent hope he doesnt turn into an...  \n",
       "2    0    its so heartbreaking look at sancho playi...  \n",
       "3    0    wish him well in manchester united\n",
       "Name: ...  \n",
       "4    0    one of the most talented players bundesli...  \n",
       "..                                                 ...  \n",
       "190  0    has potential to be the next ronaldomessi...  \n",
       "191  0    sancho 3 thank you\n",
       "Name: comment_clean, d...  \n",
       "192  0    welcome to manchester united the theatre ...  \n",
       "193  0    i hope he became much stronger and health...  \n",
       "194  0    all i can say is good luck on your next d...  \n",
       "\n",
       "[195 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos = []\n",
    "comments = []\n",
    "for id in comments_df[\"video_id\"]:\n",
    "    print(id)\n",
    "    result = fetch_all_info(id, API_KEY)\n",
    "    if result:\n",
    "        comment, info = result\n",
    "        infos.append(info)\n",
    "        comments.append(comment)\n",
    "infos = pd.concat(infos)\n",
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3aa9c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>likecount</th>\n",
       "      <th>date</th>\n",
       "      <th>replies</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I never worry about life life„ÅÆ„Å®„Åì„Çç„ÅÆËìÆÂêõ„ÅÆÂ£∞„Åå„Åô„Åî„ÅèÂ•Ω„Åç„Åß„ÅôÔºÅ</td>\n",
       "      <td>colors</td>\n",
       "      <td>332</td>\n",
       "      <td>2021-03-06T05:13:15Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    I never worry about life life„ÅÆ„Å®„Åì„Çç„ÅÆËìÆÂêõ„ÅÆÂ£∞„Åå„Åô„Åî...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy 2nd Anniversary \"Young\" PERFORMANCE</td>\n",
       "      <td>stan 500 groups and soloist of pop asian and eng</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-03-03T22:20:37Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0    Happy 2nd Anniversary \"Young\" PERFORMANCE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment  \\\n",
       "0  I never worry about life life„ÅÆ„Å®„Åì„Çç„ÅÆËìÆÂêõ„ÅÆÂ£∞„Åå„Åô„Åî„ÅèÂ•Ω„Åç„Åß„ÅôÔºÅ   \n",
       "1        Happy 2nd Anniversary \"Young\" PERFORMANCE   \n",
       "\n",
       "                                             author  likecount  \\\n",
       "0                                            colors        332   \n",
       "1  stan 500 groups and soloist of pop asian and eng          6   \n",
       "\n",
       "                   date  replies  \\\n",
       "0  2021-03-06T05:13:15Z        0   \n",
       "1  2023-03-03T22:20:37Z        0   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0  0    I never worry about life life„ÅÆ„Å®„Åì„Çç„ÅÆËìÆÂêõ„ÅÆÂ£∞„Åå„Åô„Åî...  \n",
       "1  0    Happy 2nd Anniversary \"Young\" PERFORMANCE...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7620c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "33ae9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add video Id to infos dataframe ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> parent of 2b6d186 (Iterating over API keys on stats)
   "id": "b172a372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_newline(text):\n",
    "    text = text.replace('\\n', '') \n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for punctuation in string.punctuation: \n",
    "        text = text.replace(punctuation, '') \n",
    "    return text\n",
    "\n",
    "def lowercase (text): \n",
    "    lowercased = text.lower() \n",
    "    return lowercased\n",
    "\n",
    "for df in comments:\n",
    "    df['comment_clean'] = df.comment.apply(remove_newline)\n",
    "    df['comment_clean'] = df.comment_clean.apply(remove_punctuation)\n",
    "    df['comment_clean'] = df.comment_clean.apply(lowercase)\n",
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7854f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('words')\n",
    "\n",
    "english_words = set(words.words())\n",
    "def is_english(text):\n",
    "    words_in_comment = word_tokenize(text)\n",
    "    num_words_in_comment = len(words_in_comment)\n",
    "    num_english_words_in_comment = 0\n",
    "    for word in words_in_comment:\n",
    "        if word in english_words:\n",
    "            num_english_words_in_comment += 1\n",
    "    english = False\n",
    "    if num_english_words_in_comment/num_words_in_comment >= 0.3:\n",
    "        english = True\n",
    "    return english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(\"ÊÄñ„Åè„Å¶„ÇÇah ah Êï£„Çã„ÅÆ„ÅïËèØÈ∫ó„Å´Áæé„Åó„Åèüé∂ Â§ßÂ•Ω„Åç„Åß„Åôüòç\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_only(df):\n",
    "    df['english'] = df['comment_clean'].apply(is_english)\n",
    "    return df\n",
    "    \n",
    "for df in comments:\n",
    "    df = english_only(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34f2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comments[3][comments[3][\"english\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_english_symbols(text):\n",
    "    english_pattern = re.compile(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]')\n",
    "    cleaned_text = re.sub(english_pattern, '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68503800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for df in comments:\n",
    "    df['comment_clean'] = df.comment_clean.apply(remove_non_english_symbols)\n",
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73230b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[3][comments[3][\"english\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f021caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_english_symbols(\"i never worry about life life„ÅÆ„Å®„Åì„Çç„ÅÆËìÆÂêõ„ÅÆÂ£∞„Åå„Åô„Åî„ÅèÂ•Ω„Åç„Åß„ÅôÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d798bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = comments[0].drop(\"comment_clean\",axis=1).drop(\"english\",axis=1)\n",
    "example_clean_filtered = clean_and_filter(example)\n",
    "example_clean_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
